# ğŸ•‰ï¸ TukaTranslate: Translating Saint Tukaram's Ovis Using NLP

This project aims to translate the deeply spiritual ovis (verses) of Sant Tukaram, a revered saint of the Bhakti movement, from Marathi to English using modern Natural Language Processing (NLP) techniques.

Sant Tukaramâ€™s poetry is rich in metaphor, devotion, and cultural nuance â€” making it both a linguistic and spiritual challenge to translate. While traditional machine translation focuses on literal accuracy, this project embraces a meaning-preserving approach by comparing manually translated ovis with outputs from a pretrained MarianMT model

---

## ğŸ” Project Objectives

- Translate 100 ovis from Marathi to English using Hugging Face's `MarianMT` model (`opus-mt-mr-en`)
- Evaluate translation quality using the **ROUGE-L metric**, more suited to poetic and paraphrased text
- Highlight the limitations of machine translation for devotional literature
- Encourage human-AI collaboration for culturally significant NLP tasks

---

## âœ¨ Why This Matters

Preserving Sant Tukaram's spiritual legacy and making it accessible globally through AI enables:

- **Cultural preservation** of Marathi literature.
- **Cross-lingual understanding** of Bhakti-era spirituality.
- A bridge between **ancient wisdom and modern technology**.
- Preserving and sharing Tukaram's verses with a wider, global audience helps bridge **language, culture, and time**. By combining **ancient wisdom** with **modern AI**, this project attempts to digitally honor a saint whose words still inspire millions.


---

## ğŸ“š Dataset

- Contains 100 Ovis with the following columns:
  - `ovi_marathi`: Original Ovi in Marathi (Devanagari script)
  - `ovi_english`: Manual English Translation
  - `translated_by_model`: Output from MarianMT model
  - `rougeL_score`: ROUGE-L F1 score for each model vs. manual translation

---

## ğŸ§  Model Details

- **Model used**: `Helsinki-NLP/opus-mt-mr-en` (Marathi to English)
- **Library**: Hugging Face Transformers
- **Backend**: PyTorch

```python
from transformers import MarianMTModel, MarianTokenizer

model_name = "Helsinki-NLP/opus-mt-mr-en"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)
```

---

## ğŸ“ˆ Evaluation Metric

- Used **ROUGE-L F1 Score** to evaluate translation quality.
- Captures semantic similarity via **longest common subsequence**.
- Chosen over BLEU due to better alignment with poetic structure.

---

## ğŸ“Š Key Results

| Metric               | Value     |
|----------------------|-----------|
| Avg. ROUGE-L Score   | 0.0894    |
| Max Score Observed   | ~0.3      |
| Translation Quality  | Modest    |

### Sample Comparison

```
ğŸ”¸ Marathi Ovi:
à¤¤à¥à¤•à¤¾ à¤®à¥à¤¹à¤£à¥‡ à¤®à¤¾à¤—à¤£à¥‡ à¤¦à¥‡à¤µà¤¾ à¥¤ à¤¤à¥à¤à¤¾ à¤µà¤¿à¤¸à¤° à¤¨à¤•à¥‹ à¤®à¤œ à¥¥

âœ… Manual English:
Tuka says, O Lord, all I ask is â€” never let me forget You.

ğŸ¤– Model English:
Don't pay attention to your identity.
```

---

## âš ï¸ Observations

- Model struggled with metaphor-rich, emotionally nuanced content.
- Some translations were overly generic or contextually incorrect.
- ROUGE-L was more effective than BLEU for this task.
- Pretrained models require **fine-tuning on devotional data** for better results.

---

## ğŸš€ Future Scope

- Fine-tune MarianMT on a **larger corpus of Marathi devotional texts**.
- Explore **IndicTrans2** or **human-AI post-editing pipelines**.
- Apply **Named Entity Recognition (NER)** to extract spiritual references.
- Build a **web-based Ovi translator or visualizer** using Streamlit or Flask.

---

## ğŸ“‚ Folder Structure

```
ğŸ“ NLP_Saint_Tukaram/
â”‚
â”œâ”€â”€ tukaram_ovis.xlsx               # Dataset of 100 Ovis
â”œâ”€â”€ NLP_Saint_Tukaram.ipynb         # Translation & evaluation notebook
â”œâ”€â”€ NLP Saint Tukaram.ipynb - Colab.pdf  # Exported notebook (PDF)
â”œâ”€â”€ README.md                       # Project documentation
```

---

## ğŸ™ Acknowledgements

- Sant Tukaram Maharaj and the Bhakti movement
- HuggingFace Transformers team
- Marathi literary translators and scholars

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).
