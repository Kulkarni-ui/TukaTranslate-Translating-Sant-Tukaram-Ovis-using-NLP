{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🕉️ TukaTranslate: Translating Sant Tukaram's Ovis using NLP\n",
        "\n",
        "This project aims to translate the deeply spiritual **ovis** (verses) of **Sant Tukaram**, a revered saint of the Bhakti movement, from **Marathi to English** using modern **Natural Language Processing (NLP)** techniques.\n",
        "\n",
        "Sant Tukaram’s poetry is rich in metaphor, devotion, and cultural nuance — making it both a linguistic and spiritual challenge to translate. While traditional machine translation focuses on literal accuracy, this project embraces a **meaning-preserving approach** by comparing **manually translated ovis** with outputs from a **pretrained MarianMT model**.\n",
        "\n",
        "### 🔍 Project Goals\n",
        "- Translate 100 ovis from Marathi to English using Hugging Face's `MarianMT` model (`opus-mt-mr-en`)\n",
        "- Evaluate translation quality using the **ROUGE-L metric**, more suited to poetic and paraphrased text\n",
        "- Highlight the limitations of machine translation for devotional literature\n",
        "- Encourage human-AI collaboration for culturally significant NLP tasks\n",
        "\n",
        "### ✨ Why This Matters\n",
        "Preserving and sharing Tukaram's verses with a wider, global audience helps bridge **language, culture, and time**. By combining **ancient wisdom** with **modern AI**, this project attempts to digitally honor a saint whose words still inspire millions.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "G7rT8pHje3zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installs Hugging Face’s transformers (for MarianMT model)**\n",
        "\n",
        "**sentencepiece: needed by the tokenizer**\n",
        "\n",
        "**torch: PyTorch backend for model inference**"
      ],
      "metadata": {
        "id": "9bCEnd9kfOlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EP1m0hXO4Kb",
        "outputId": "2119dbc6-766c-4b6e-ce96-d28d014ff96e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing The Dataset of Saint Tukaram's Ovis (100)**"
      ],
      "metadata": {
        "id": "GTHQq4B-fdmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load  dataset\n",
        "df = pd.read_excel(\"/content/tukaram_ovis.xlsx\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dGY-xDfJP6w3",
        "outputId": "5dc6c59d-20a6-4c94-b544-b3dd2ea1579a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     ovi_marathi  \\\n",
              "0     तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥   \n",
              "1    जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥   \n",
              "2    नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥   \n",
              "3  काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥   \n",
              "4      तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥   \n",
              "\n",
              "                                         ovi_english  \n",
              "0  Tuka says, O Lord, all I ask is — never let me...  \n",
              "1  Wherever I go, You are there. You are my desti...  \n",
              "2       Chanting Your name brings peace to the soul.  \n",
              "3  How can I describe Your miracles? Words always...  \n",
              "4  Tuka says, You alone are mighty. Shelter the h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1390d455-1119-4573-971d-274e8b86d4c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ovi_marathi</th>\n",
              "      <th>ovi_english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥</td>\n",
              "      <td>Tuka says, O Lord, all I ask is — never let me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥</td>\n",
              "      <td>Wherever I go, You are there. You are my desti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥</td>\n",
              "      <td>Chanting Your name brings peace to the soul.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥</td>\n",
              "      <td>How can I describe Your miracles? Words always...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥</td>\n",
              "      <td>Tuka says, You alone are mighty. Shelter the h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1390d455-1119-4573-971d-274e8b86d4c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1390d455-1119-4573-971d-274e8b86d4c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1390d455-1119-4573-971d-274e8b86d4c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-90fbc959-4fa0-475c-bd1d-3bb0fa5355c1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90fbc959-4fa0-475c-bd1d-3bb0fa5355c1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-90fbc959-4fa0-475c-bd1d-3bb0fa5355c1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ovi_marathi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u091c\\u093f\\u0925\\u0947 \\u091c\\u093e\\u0908 \\u0924\\u093f\\u0925\\u0947 \\u0924\\u0942\\u091a\\u093f \\u0906\\u0939\\u0947\\u0938 \\u0964 \\u092e\\u091c\\u0932\\u093e\\u091a\\u093f \\u0924\\u0942 \\u0920\\u093f\\u0915\\u093e\\u0923 \\u0965\",\n          \"\\u0924\\u0941\\u0915\\u093e \\u092e\\u094d\\u0939\\u0923\\u0947 \\u0924\\u0942\\u091a\\u093f \\u0938\\u092e\\u0930\\u094d\\u0925 \\u0964 \\u092e\\u091c \\u0926\\u0940\\u0928\\u093e\\u0932\\u093e \\u0906\\u0936\\u094d\\u0930\\u092f \\u0965\",\n          \"\\u0928\\u093e\\u092e \\u0918\\u0947\\u0924\\u0932\\u0947 \\u0924\\u0941\\u091d\\u0902 \\u091c\\u0940\\u0935\\u093e \\u0964 \\u0936\\u093e\\u0902\\u0924\\u093f \\u0932\\u093e\\u092d\\u0947 \\u0905\\u0902\\u0924\\u0903\\u0915\\u0930\\u0923\\u093e \\u0965\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ovi_english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Wherever I go, You are there. You are my destination.\",\n          \"Tuka says, You alone are mighty. Shelter the humble like me.\",\n          \"Chanting Your name brings peace to the soul.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loads MarianMT model fine-tuned for Marathi to English**\n",
        "\n",
        "**Tokenizer converts Marathi text into input format expected by the model**"
      ],
      "metadata": {
        "id": "uy3Srm1lfsRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load Marathi to English translation model\n",
        "model_name = \"Helsinki-NLP/opus-mt-mr-en\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KiQkwhfQjpa",
        "outputId": "d0eb5054-2389-423a-9da9-86bfcc1f6741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This function:**\n",
        "\n",
        "\n",
        "* **Takes a list of Marathi strings**\n",
        "* **Returns a list of translated strings**\n",
        "* **Decodes model output back to human-readable text**\n",
        "* **Generates English output with the model**\n",
        "* **Converts each to tokens using the tokenizer**\n",
        "* **Returns a list of translated strings**\n"
      ],
      "metadata": {
        "id": "SXGaxArkfxdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_ovis(marathi_texts):\n",
        "    translated = []\n",
        "    for text in marathi_texts:\n",
        "        batch = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n",
        "        gen = model.generate(**batch)\n",
        "        out = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "        translated.append(out[0])\n",
        "    return translated"
      ],
      "metadata": {
        "id": "KjAH163oQmlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translates all ovis in the \"ovi_marathi\" column**\n",
        "\n",
        "**Stores output in a new column: \"translated_by_model\"**"
      ],
      "metadata": {
        "id": "UurW6Z2fgXee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marathi_ovis = df[\"ovi_marathi\"].tolist()\n",
        "model_translations = translate_ovis(marathi_ovis)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"translated_by_model\"] = model_translations\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8cc2eupJQ47m",
        "outputId": "77e41d55-b24f-476e-9964-b28ddd196f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4073: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     ovi_marathi  \\\n",
              "0     तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥   \n",
              "1    जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥   \n",
              "2    नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥   \n",
              "3  काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥   \n",
              "4      तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥   \n",
              "\n",
              "                                         ovi_english  \\\n",
              "0  Tuka says, O Lord, all I ask is — never let me...   \n",
              "1  Wherever I go, You are there. You are my desti...   \n",
              "2       Chanting Your name brings peace to the soul.   \n",
              "3  How can I describe Your miracles? Words always...   \n",
              "4  Tuka says, You alone are mighty. Shelter the h...   \n",
              "\n",
              "                                 translated_by_model  \n",
              "0               Don't pay attention to your identity  \n",
              "1  You are at the top of the hill, and you are at...  \n",
              "2  Let your will take place, as in heaven, also u...  \n",
              "3  Keep your lips open when speaking with your to...  \n",
              "4  You will also be a friend to the poor, and a f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc790331-b73a-4262-9c3d-f18320191509\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ovi_marathi</th>\n",
              "      <th>ovi_english</th>\n",
              "      <th>translated_by_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥</td>\n",
              "      <td>Tuka says, O Lord, all I ask is — never let me...</td>\n",
              "      <td>Don't pay attention to your identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥</td>\n",
              "      <td>Wherever I go, You are there. You are my desti...</td>\n",
              "      <td>You are at the top of the hill, and you are at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥</td>\n",
              "      <td>Chanting Your name brings peace to the soul.</td>\n",
              "      <td>Let your will take place, as in heaven, also u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥</td>\n",
              "      <td>How can I describe Your miracles? Words always...</td>\n",
              "      <td>Keep your lips open when speaking with your to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥</td>\n",
              "      <td>Tuka says, You alone are mighty. Shelter the h...</td>\n",
              "      <td>You will also be a friend to the poor, and a f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc790331-b73a-4262-9c3d-f18320191509')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc790331-b73a-4262-9c3d-f18320191509 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc790331-b73a-4262-9c3d-f18320191509');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-afc022d2-f903-43d7-8c9d-1d9fe8d908fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afc022d2-f903-43d7-8c9d-1d9fe8d908fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-afc022d2-f903-43d7-8c9d-1d9fe8d908fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ovi_marathi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u091c\\u093f\\u0925\\u0947 \\u091c\\u093e\\u0908 \\u0924\\u093f\\u0925\\u0947 \\u0924\\u0942\\u091a\\u093f \\u0906\\u0939\\u0947\\u0938 \\u0964 \\u092e\\u091c\\u0932\\u093e\\u091a\\u093f \\u0924\\u0942 \\u0920\\u093f\\u0915\\u093e\\u0923 \\u0965\",\n          \"\\u0924\\u0941\\u0915\\u093e \\u092e\\u094d\\u0939\\u0923\\u0947 \\u0924\\u0942\\u091a\\u093f \\u0938\\u092e\\u0930\\u094d\\u0925 \\u0964 \\u092e\\u091c \\u0926\\u0940\\u0928\\u093e\\u0932\\u093e \\u0906\\u0936\\u094d\\u0930\\u092f \\u0965\",\n          \"\\u0928\\u093e\\u092e \\u0918\\u0947\\u0924\\u0932\\u0947 \\u0924\\u0941\\u091d\\u0902 \\u091c\\u0940\\u0935\\u093e \\u0964 \\u0936\\u093e\\u0902\\u0924\\u093f \\u0932\\u093e\\u092d\\u0947 \\u0905\\u0902\\u0924\\u0903\\u0915\\u0930\\u0923\\u093e \\u0965\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ovi_english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Wherever I go, You are there. You are my destination.\",\n          \"Tuka says, You alone are mighty. Shelter the humble like me.\",\n          \"Chanting Your name brings peace to the soul.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translated_by_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"You are at the top of the hill, and you are at the top of the hill!\",\n          \"You will also be a friend to the poor, and a friend to the needy.\",\n          \"Let your will take place, as in heaven, also upon earth. \\\" - Matthew 6: 9, 10.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  # Preview first 5 comparisons\n",
        "    print(f\"🔸 Marathi Ovi: {df['ovi_marathi'][i]}\")\n",
        "    print(f\"✅ Manual English: {df['ovi_english'][i]}\")\n",
        "    print(f\"🤖 Model English: {df['translated_by_model'][i]}\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tp_rcEVQ6hd",
        "outputId": "6f822836-b8c4-4531-e3b8-6dee9ac1fcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔸 Marathi Ovi: तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥\n",
            "✅ Manual English: Tuka says, O Lord, all I ask is — never let me forget You.\n",
            "🤖 Model English: Don't pay attention to your identity\n",
            "======================================================================\n",
            "🔸 Marathi Ovi: जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥\n",
            "✅ Manual English: Wherever I go, You are there. You are my destination.\n",
            "🤖 Model English: You are at the top of the hill, and you are at the top of the hill!\n",
            "======================================================================\n",
            "🔸 Marathi Ovi: नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥\n",
            "✅ Manual English: Chanting Your name brings peace to the soul.\n",
            "🤖 Model English: Let your will take place, as in heaven, also upon earth. \" - Matthew 6: 9, 10.\n",
            "======================================================================\n",
            "🔸 Marathi Ovi: काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥\n",
            "✅ Manual English: How can I describe Your miracles? Words always fall short.\n",
            "🤖 Model English: Keep your lips open when speaking with your tongue\n",
            "======================================================================\n",
            "🔸 Marathi Ovi: तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥\n",
            "✅ Manual English: Tuka says, You alone are mighty. Shelter the humble like me.\n",
            "🤖 Model English: You will also be a friend to the poor, and a friend to the needy.\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializes a ROUGE scorer for ROUGE-L**\n",
        "\n",
        "**For each pair of reference (manual) and model translation:**\n",
        "\n",
        "\n",
        "*  **Calculates ROUGE-L F1 score**\n",
        "*  **Stores scores in the DataFrame**\n"
      ],
      "metadata": {
        "id": "v4s0DkELgfVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "scores = [\n",
        "    scorer.score(df['ovi_english'][i], df['translated_by_model'][i])['rougeL'].fmeasure\n",
        "    for i in range(len(df))\n",
        "]\n",
        "\n",
        "df['rougeL_score'] = scores\n",
        "df[['ovi_marathi', 'rougeL_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "rFhrTIzGRU_d",
        "outputId": "30ab5647-52f6-4afc-8a63-997a59ea23d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      ovi_marathi  rougeL_score\n",
              "0      तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥      0.000000\n",
              "1     जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥      0.296296\n",
              "2     नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥      0.086957\n",
              "3   काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥      0.105263\n",
              "4       तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥      0.153846\n",
              "..                                            ...           ...\n",
              "95    नाम घेता विसरते दु:ख । पांडुरंग पावला सहज ॥      0.000000\n",
              "96      घेईन उचलून कष्ट । पांडुरंगा मज भक्ती दे ॥      0.000000\n",
              "97              जीव देईन उधळून । परि सोडीन नामा ॥      0.050000\n",
              "98           तुझ्या नामात गोडी । लागली जीवा फार ॥      0.137931\n",
              "99           माझा मेळा तुझ्याशी । इतर संगती नको ॥      0.076923\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0eaa2b4-ba55-491c-bbb7-c2121112fe31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ovi_marathi</th>\n",
              "      <th>rougeL_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तुका म्हणे मागणे देवा । तुझा विसर नको मज ॥</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जिथे जाई तिथे तूचि आहेस । मजलाचि तू ठिकाण ॥</td>\n",
              "      <td>0.296296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>नाम घेतले तुझं जीवा । शांति लाभे अंतःकरणा ॥</td>\n",
              "      <td>0.086957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>काय म्हणावे तुझ्या लीला । शब्द अपुरे नेहमीस ॥</td>\n",
              "      <td>0.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>तुका म्हणे तूचि समर्थ । मज दीनाला आश्रय ॥</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>नाम घेता विसरते दु:ख । पांडुरंग पावला सहज ॥</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>घेईन उचलून कष्ट । पांडुरंगा मज भक्ती दे ॥</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>जीव देईन उधळून । परि सोडीन नामा ॥</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>तुझ्या नामात गोडी । लागली जीवा फार ॥</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>माझा मेळा तुझ्याशी । इतर संगती नको ॥</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0eaa2b4-ba55-491c-bbb7-c2121112fe31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0eaa2b4-ba55-491c-bbb7-c2121112fe31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0eaa2b4-ba55-491c-bbb7-c2121112fe31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d0c7d0ee-85ed-42c9-a987-569c4bea44d7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0c7d0ee-85ed-42c9-a987-569c4bea44d7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d0c7d0ee-85ed-42c9-a987-569c4bea44d7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['ovi_marathi', 'rougeL_score']]\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"ovi_marathi\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"\\u091d\\u094b\\u0915\\u093e \\u0926\\u093f\\u0932\\u093e \\u0917\\u0917\\u0928\\u093e\\u0924 \\u0964 \\u0924\\u0941\\u0915\\u093e \\u092e\\u094d\\u0939\\u0923\\u0947 \\u091a\\u0922\\u0932\\u094b \\u092e\\u093e\\u0924 \\u0965\",\n          \"\\u092a\\u093e\\u0902\\u0921\\u0941\\u0930\\u0902\\u0917\\u093e\\u091a\\u094d\\u092f\\u093e \\u0917\\u091c\\u0930\\u093e\\u0924 \\u0964 \\u0935\\u093f\\u0938\\u0930\\u0932\\u0947 \\u0939\\u0947 \\u091c\\u0917 \\u0938\\u0917\\u0933\\u0902 \\u0965\",\n          \"\\u0926\\u0947\\u0939 \\u0935\\u093e\\u0939\\u0940\\u0928 \\u0924\\u0941\\u091d\\u094d\\u092f\\u093e \\u0938\\u0947\\u0935\\u0947\\u0938\\u093e\\u0920\\u0940 \\u0964 \\u0928\\u093e\\u092e\\u093e\\u0924 \\u0935\\u093f\\u0938\\u0930\\u0942\\u0928 \\u091c\\u093e\\u0924\\u094b \\u0965\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07012356643593033,\n        \"min\": 0.0,\n        \"max\": 0.29629629629629634,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.1,\n          0.03921568627450981,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "_df_3['rougeL_score'].plot(kind='line', figsize=(8, 4), title='rougeL_score')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "9OmZ9EADaYR6",
        "outputId": "3536c5f2-3cfb-4353-a3db-a96c43767e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "_df_2['rougeL_score'].plot(kind='hist', bins=20, title='rougeL_score')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6Ew8jAhvaWiy",
        "outputId": "72f79e63-9958-4a01-8601-961c6dc20584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGzCAYAAAA1yP25AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKIZJREFUeJzt3Xt0VOW9xvFnSMhwywUMkOSACYSLigIHPaZZhgomGi6lIODhoiVYpLVFCwaOBbEC4iKAGqgtwqGVm21FrIg9B0EgBDiHIiw0QAFFiFxEknBrEgglYPKePzhMHRMiM8xk5g3fz1p7mXn3O+/+7XftbB737D1xGGOMAAAALFQv0AUAAAB4iyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEQ9KZOnSqHw6HTp08HuhQAQYYgAwAArEWQAW5iZWVlgS7hplJZWamLFy8GugygTiHIADeJqx/P7N+/X8OHD1fTpk2VkpKir7/+WtOnT1diYqKcTqcSEhL03HPPqby83O39DodDU6dOrTJuQkKCRo4c6da2Z88e3X///WrYsKFatWqll156SYsXL5bD4dCRI0fc+q5Zs0bdu3dX48aNFR4err59+2rfvn0+3vsr1q9fr5SUFEVFRalJkybq2LGjnnvuObc+Fy9e1NSpU9WhQwc1aNBAsbGxGjhwoPLz8119ysrKNH78eLVu3VpOp1MdO3bUK6+8ImOM21gOh0NPPfWU/vjHP6pTp05yOp1au3atJOmrr77Sj3/8Y7Vs2VJOp1OdOnXSokWL/LLfQF0WGugCANSuRx55RO3bt9eMGTNkjNETTzyhpUuXavDgwRo/fry2b9+urKwsffrpp3rvvfc8Hv+rr75Sz5495XA4NGnSJDVu3Fi///3v5XQ6q/R98803lZGRofT0dM2aNUsXLlzQ/PnzlZKSory8PCUkJPhgj6/Yt2+ffvCDH6hz58568cUX5XQ6dejQIW3dutXVp6KiQj/4wQ+Uk5OjoUOHauzYsTp37pzWr1+vvXv3KjExUcYY/fCHP1Rubq5GjRqlrl276sMPP9R//Md/6KuvvtKcOXPctrtx40atWLFCTz31lKKjo5WQkKCioiJ973vfcwWd5s2ba82aNRo1apRKS0s1btw4n+03UOcZADeFKVOmGElm2LBhrrZdu3YZSeaJJ55w6zthwgQjyWzcuNHVJslMmTKlyrjx8fEmIyPD9frpp582DofD5OXludrOnDljmjVrZiSZw4cPG2OMOXfunImKijKjR492G6+wsNBERka6tV+t/dSpU17s+RVz5sz5zjEWLVpkJJns7Owq6yorK40xxqxatcpIMi+99JLb+sGDBxuHw2EOHTrkapNk6tWrZ/bt2+fWd9SoUSY2NtacPn3arX3o0KEmMjLSXLhwweP9A25WfLQE3GSefPJJ188ffPCBJCkzM9Otz/jx4yVJq1ev9nj8tWvXKjk5WV27dnW1NWvWTI8++qhbv/Xr16u4uFjDhg3T6dOnXUtISIiSkpKUm5vr8bZrEhUVJUl6//33VVlZWW2fd999V9HR0Xr66aerrHM4HJKuzFlISIh+8YtfuK0fP368jDFas2aNW/v999+vO+64w/XaGKN3331X/fr1kzHGbd/T09NVUlKiTz755EZ2Fbip8NEScJNp06aN6+ejR4+qXr16ateunVufmJgYRUVF6ejRox6Pf/ToUSUnJ1dp//Y2Dh48KEl64IEHqh0nIiLC423XZMiQIfr973+vJ554QhMnTlRqaqoGDhyowYMHq169K/9Pl5+fr44dOyo09NqnxqNHjyouLk7h4eFu7bfffrtr/Td9c74l6dSpUyouLtbChQu1cOHCardx8uRJj/cPuFkRZICbTMOGDau0Xb3a4I2Kigqv3nf1qsibb76pmJiYKutrChPeaNiwobZs2aLc3FytXr1aa9eu1dtvv60HHnhA69atU0hIiE+3983tftPV/X7ssceUkZFR7Xs6d+7sl1qAuoggA9zE4uPjVVlZqYMHD7quKEhSUVGRiouLFR8f72pr2rSpiouL3d5/6dIlFRQUVBnz0KFDVbb17bbExERJUosWLZSWlnaju3Jd6tWrp9TUVKWmpio7O1szZszQ5MmTlZubq7S0NCUmJmr79u26fPmy6tevX+0Y8fHx2rBhg86dO+d2Veazzz5zra9J8+bNFR4eroqKilrbb6Au4x4Z4CbWp08fSdLcuXPd2rOzsyVJffv2dbUlJiZqy5Ytbv0WLlxY5YpMenq6tm3bpl27drnazp49qz/+8Y9V+kVERGjGjBm6fPlyldpOnTrl8f7U5OzZs1Xart7Hc/VR80GDBun06dP67W9/W6Wv+f9Hq/v06aOKiooqfebMmSOHw6HevXvXWEdISIgGDRqkd999V3v37q2y3tf7DdR1XJEBbmJdunRRRkaGFi5cqOLiYt1///3asWOHli5dqgEDBqhnz56uvk888YSefPJJDRo0SA8++KB2796tDz/8UNHR0W5jPvvss/rDH/6gBx98UE8//bTr8etbb71VZ8+edX2MFRERofnz5+tHP/qRunXrpqFDh6p58+Y6duyYVq9erfvuu69KWMjOzlajRo3c2urVq1flu2Cq8+KLL2rLli3q27ev4uPjdfLkSb3++utq1aqVUlJSJEkjRozQsmXLlJmZqR07dqh79+4qKyvThg0b9POf/1z9+/dXv3791LNnT02ePFlHjhxRly5dtG7dOr3//vsaN26c60pTTWbOnKnc3FwlJSVp9OjRuuOOO3T27Fl98skn2rBhQ7WhC8A1BPahKQC15VqPMF++fNlMmzbNtGnTxtSvX9+0bt3aTJo0yVy8eNGtX0VFhfnlL39poqOjTaNGjUx6ero5dOhQlcevjTEmLy/PdO/e3TidTtOqVSuTlZVlXnvtNSPJFBYWuvXNzc016enpJjIy0jRo0MAkJiaakSNHmp07d1apvbolJCTkuvY/JyfH9O/f38TFxZmwsDATFxdnhg0bZj7//HO3fhcuXDCTJ092zUdMTIwZPHiwyc/Pd/U5d+6ceeaZZ0xcXJypX7++ad++vXn55Zddj2hfJcmMGTOm2nqKiorMmDFjTOvWrV3bSU1NNQsXLryu/QFwhcOYb30VJQD4wbhx4/Sf//mfOn/+vN9urAVw8+EeGQA+949//MPt9ZkzZ/Tmm28qJSWFEAPAp7hHBoDPJScnq0ePHrr99ttVVFSkN954Q6WlpfrVr37ll+0VFhbWuL5hw4aKjIz0y7YBBBYfLQHwueeee05//vOfdfz4cTkcDnXr1k1Tpkzx2+PG3/U9OBkZGVqyZIlftg0gsAgyAKy3YcOGGtfHxcW5/ZkAAHUHQQYAAFiLm30BAIC16nyQMcaotLRUXHgCAKDuqfNB5ty5c4qMjNS5c+cCXQoAAPCxOh9kAABA3UWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFgrNNAF2Cxh4mq/jX1kZl+/jQ0AQF3BFRkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFgroEEmKytL//Zv/6bw8HC1aNFCAwYM0IEDB9z6XLx4UWPGjNEtt9yiJk2aaNCgQSoqKgpQxQAAIJgENMhs3rxZY8aM0UcffaT169fr8uXLeuihh1RWVubq88wzz+i//uu/9M4772jz5s06ceKEBg4cGMCqAQBAsHAYY0ygi7jq1KlTatGihTZv3qzvf//7KikpUfPmzfWnP/1JgwcPliR99tlnuv3227Vt2zZ973vf+84xS0tLFRkZqZKSEkVERPi03oSJq3063jcdmdnXb2MDAFBXBNU9MiUlJZKkZs2aSZI+/vhjXb58WWlpaa4+t912m2699VZt27at2jHKy8tVWlrqtgAAgLopaIJMZWWlxo0bp/vuu0933nmnJKmwsFBhYWGKiopy69uyZUsVFhZWO05WVpYiIyNdS+vWrf1dOgAACJCgCTJjxozR3r17tXz58hsaZ9KkSSopKXEtX375pY8qBAAAwSY00AVI0lNPPaX//u//1pYtW9SqVStXe0xMjC5duqTi4mK3qzJFRUWKiYmpdiyn0ymn0+nvkgEAQBAI6BUZY4yeeuopvffee9q4caPatGnjtv7uu+9W/fr1lZOT42o7cOCAjh07puTk5NouFwAABJmAXpEZM2aM/vSnP+n9999XeHi4676XyMhINWzYUJGRkRo1apQyMzPVrFkzRURE6Omnn1ZycvJ1PbEEAADqtoAGmfnz50uSevTo4da+ePFijRw5UpI0Z84c1atXT4MGDVJ5ebnS09P1+uuv13KlAAAgGAXV98j4A98jAwBA3RU0Ty0BAAB4iiADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQIaZLZs2aJ+/fopLi5ODodDq1atcls/cuRIORwOt6VXr16BKRYAAASdgAaZsrIydenSRfPmzbtmn169eqmgoMC1vPXWW7VYIQAACGahgdx479691bt37xr7OJ1OxcTE1FJFAADAJkF/j8ymTZvUokULdezYUT/72c905syZGvuXl5ertLTUbQEAAHVTUAeZXr16admyZcrJydGsWbO0efNm9e7dWxUVFdd8T1ZWliIjI11L69ata7FiAABQmxzGGBPoIiTJ4XDovffe04ABA67Z54svvlBiYqI2bNig1NTUavuUl5ervLzc9bq0tFStW7dWSUmJIiIifFpzwsTVPh3vm47M7Ou3sQEAqCuC+orMt7Vt21bR0dE6dOjQNfs4nU5FRES4LQAAoG6yKsgcP35cZ86cUWxsbKBLAQAAQSCgTy2dP3/e7erK4cOHtWvXLjVr1kzNmjXTtGnTNGjQIMXExCg/P1/PPvus2rVrp/T09ABWDQAAgkVAg8zOnTvVs2dP1+vMzExJUkZGhubPn689e/Zo6dKlKi4uVlxcnB566CFNnz5dTqczUCUDAIAgEtAg06NHD9V0r/GHH35Yi9UAAADbWHWPDAAAwDcRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADW8irIfPHFF76uAwAAwGNeBZl27dqpZ8+e+sMf/qCLFy/6uiYAAIDr4lWQ+eSTT9S5c2dlZmYqJiZGP/3pT7Vjxw5f1wYAAFAjr4JM165d9etf/1onTpzQokWLVFBQoJSUFN15553Kzs7WqVOnfF0nAABAFTd0s29oaKgGDhyod955R7NmzdKhQ4c0YcIEtW7dWiNGjFBBQYGv6gQAAKjihoLMzp079fOf/1yxsbHKzs7WhAkTlJ+fr/Xr1+vEiRPq37+/r+oEAACoItSbN2VnZ2vx4sU6cOCA+vTpo2XLlqlPnz6qV+9KLmrTpo2WLFmihIQEX9YKAADgxqsgM3/+fP34xz/WyJEjFRsbW22fFi1a6I033rih4gAAAGriVZA5ePDgd/YJCwtTRkaGN8MDAABcF6+CzOLFi9WkSRM98sgjbu3vvPOOLly4QICBNRImrvbb2Edm9vXb2ACAK7y62TcrK0vR0dFV2lu0aKEZM2bccFEAAADXw6sgc+zYMbVp06ZKe3x8vI4dO3bDRQEAAFwPr4JMixYttGfPnirtu3fv1i233HLDRQEAAFwPr4LMsGHD9Itf/EK5ubmqqKhQRUWFNm7cqLFjx2ro0KG+rhEAAKBaXt3sO336dB05ckSpqakKDb0yRGVlpUaMGME9MgAAoNZ4FWTCwsL09ttva/r06dq9e7caNmyou+66S/Hx8b6uDwAA4Jq8CjJXdejQQR06dPBVLQAAAB7xKshUVFRoyZIlysnJ0cmTJ1VZWem2fuPGjT4pDgAAoCZeBZmxY8dqyZIl6tu3r+688045HA5f1wUAAPCdvAoyy5cv14oVK9SnTx9f1wMAAHDdvHr8OiwsTO3atfN1LQAAAB7xKsiMHz9ev/71r2WM8XU9AAAA182rj5b+93//V7m5uVqzZo06deqk+vXru61fuXKlT4oDAACoiVdBJioqSg8//LCvawEAAPCIV0Fm8eLFvq4DAADAY15/Id7XX3+tTZs2KT8/X8OHD1d4eLhOnDihiIgINWnSxJc1whIJE1f7bewjM/v6bWz4H8cGAH/xKsgcPXpUvXr10rFjx1ReXq4HH3xQ4eHhmjVrlsrLy7VgwQJf1wkAAFCFV08tjR07Vvfcc4/+/ve/q2HDhq72hx9+WDk5OT4rDgAAoCZeXZH5n//5H/31r39VWFiYW3tCQoK++uornxQGAADwXby6IlNZWamKiooq7cePH1d4ePgNFwUAAHA9vAoyDz30kObOnet67XA4dP78eU2ZMoU/WwAAAGqNVx8tvfrqq0pPT9cdd9yhixcvavjw4Tp48KCio6P11ltv+bpGAACAankVZFq1aqXdu3dr+fLl2rNnj86fP69Ro0bp0Ucfdbv5FwAAwJ+8/h6Z0NBQPfbYY76sBQAAwCNeBZlly5bVuH7EiBFeFQMAAOAJr4LM2LFj3V5fvnxZFy5cUFhYmBo1akSQAQAAtcKrp5b+/ve/uy3nz5/XgQMHlJKSws2+AACg1ngVZKrTvn17zZw5s8rVGgAAAH/xWZCRrtwAfOLECV8OCQAAcE1e3SPzl7/8xe21MUYFBQX67W9/q/vuu88nhQEAAHwXr4LMgAED3F47HA41b95cDzzwgF599VVf1AUAAPCdvAoylZWVvq4DAADAYz69RwYAAKA2eXVFJjMz87r7Zmdne7MJAACA7+RVkMnLy1NeXp4uX76sjh07SpI+//xzhYSEqFu3bq5+DofDN1UCAABUw6sg069fP4WHh2vp0qVq2rSppCtfkvf444+re/fuGj9+vE+LBAAAqI5X98i8+uqrysrKcoUYSWratKleeuklnloCAAC1xqsgU1paqlOnTlVpP3XqlM6dO3fDRQEAAFwPr4LMww8/rMcff1wrV67U8ePHdfz4cb377rsaNWqUBg4c6OsaAQAAquXVPTILFizQhAkTNHz4cF2+fPnKQKGhGjVqlF5++WWfFggAAHAtXgWZRo0a6fXXX9fLL7+s/Px8SVJiYqIaN27s0+IAAABqckNfiFdQUKCCggK1b99ejRs3ljHGV3UBAAB8J6+CzJkzZ5SamqoOHTqoT58+KigokCSNGjWKR68BAECt8SrIPPPMM6pfv76OHTumRo0audqHDBmitWvXXvc4W7ZsUb9+/RQXFyeHw6FVq1a5rTfG6IUXXlBsbKwaNmyotLQ0HTx40JuSAQBAHeRVkFm3bp1mzZqlVq1aubW3b99eR48eve5xysrK1KVLF82bN6/a9bNnz9Zrr72mBQsWaPv27WrcuLHS09N18eJFb8oGAAB1jFc3+5aVlbldibnq7Nmzcjqd1z1O79691bt372rXGWM0d+5cPf/88+rfv78kadmyZWrZsqVWrVqloUOHelM6AACoQ7y6ItO9e3ctW7bM9drhcKiyslKzZ89Wz549fVLY4cOHVVhYqLS0NFdbZGSkkpKStG3btmu+r7y8XKWlpW4LAACom7y6IjN79mylpqZq586dunTpkp599lnt27dPZ8+e1datW31SWGFhoSSpZcuWbu0tW7Z0ratOVlaWpk2b5pMaAABAcPPqisydd96pzz//XCkpKerfv7/Kyso0cOBA5eXlKTEx0dc1emTSpEkqKSlxLV9++WVA6wEAAP7j8RWZy5cvq1evXlqwYIEmT57sj5okSTExMZKkoqIixcbGutqLiorUtWvXa77P6XR6dJ8OAACwl8dXZOrXr689e/b4oxY3bdq0UUxMjHJyclxtpaWl2r59u5KTk/2+fQAAEPy8+mjpscce0xtvvHHDGz9//rx27dqlXbt2Sbpyg++uXbt07NgxORwOjRs3Ti+99JL+8pe/6G9/+5tGjBihuLg4DRgw4Ia3DQAA7OfVzb5ff/21Fi1apA0bNujuu++u8jeWsrOzr2ucnTt3uj3llJmZKUnKyMjQkiVL9Oyzz6qsrEw/+clPVFxcrJSUFK1du1YNGjTwpmwAAFDHeBRkvvjiCyUkJGjv3r3q1q2bJOnzzz936+NwOK57vB49etT495kcDodefPFFvfjii56UCQAAbhIeBZn27duroKBAubm5kq78SYLXXnutyiPSAAAAtcGje2S+ffVkzZo1Kisr82lBAAAA18urm32vquljIQAAAH/zKMg4HI4q98B4ck8MAACAL3l0j4wxRiNHjnR94dzFixf15JNPVnlqaeXKlb6rEAAA4Bo8CjIZGRlurx977DGfFgMAAOAJj4LM4sWL/VUHAACAx27oZl8AAIBAIsgAAABrefUnCgAgWCRMXO2XcY/M7OuXcQH4FldkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWCg10AcD1SJi4OtAlAACCEFdkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYKDXQBQF2VMHF1oEvw2JGZfQNdAgB4hCsyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALBWUAeZqVOnyuFwuC233XZboMsCAABBIuj/aGSnTp20YcMG1+vQ0KAvGQAA1JKgTwWhoaGKiYkJdBkAACAIBfVHS5J08OBBxcXFqW3btnr00Ud17NixGvuXl5ertLTUbQEAAHVTUF+RSUpK0pIlS9SxY0cVFBRo2rRp6t69u/bu3avw8PBq35OVlaVp06bVcqUAEBwSJq72y7hHZvb1y7jAjQrqKzK9e/fWI488os6dOys9PV0ffPCBiouLtWLFimu+Z9KkSSopKXEtX375ZS1WDAAAalNQX5H5tqioKHXo0EGHDh26Zh+n0ymn01mLVQEAgEAJ6isy33b+/Hnl5+crNjY20KUAAIAgENRBZsKECdq8ebOOHDmiv/71r3r44YcVEhKiYcOGBbo0AAAQBIL6o6Xjx49r2LBhOnPmjJo3b66UlBR99NFHat68eaBLAwAAQSCog8zy5csDXQIAAAhiQf3REgAAQE0IMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1QgNdAGpfwsTVgS4BQYpjAwgsG38Hj8zsG9Dtc0UGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWsiLIzJs3TwkJCWrQoIGSkpK0Y8eOQJcEAACCQNAHmbfffluZmZmaMmWKPvnkE3Xp0kXp6ek6efJkoEsDAAABFvRBJjs7W6NHj9bjjz+uO+64QwsWLFCjRo20aNGiQJcGAAACLDTQBdTk0qVL+vjjjzVp0iRXW7169ZSWlqZt27ZV+57y8nKVl5e7XpeUlEiSSktLfV5fZfkFn495lT/qvcqfdQN1hT9/B/3JX7/fts6HbWw8P/v72AgPD5fD4bjm+qAOMqdPn1ZFRYVatmzp1t6yZUt99tln1b4nKytL06ZNq9LeunVrv9ToL5FzA10BcHPjd9Ad84Fr8fexUVJSooiIiGuuD+og441JkyYpMzPT9bqyslJnz57VLbfcUmOi81Rpaalat26tL7/8ssYJxj8xZ55hvjzDfHmG+fIM8+UZX85XeHh4jeuDOshER0crJCRERUVFbu1FRUWKiYmp9j1Op1NOp9OtLSoqyl8lKiIigoPaQ8yZZ5gvzzBfnmG+PMN8eaY25iuob/YNCwvT3XffrZycHFdbZWWlcnJylJycHMDKAABAMAjqKzKSlJmZqYyMDN1zzz269957NXfuXJWVlenxxx8PdGkAACDAgj7IDBkyRKdOndILL7ygwsJCde3aVWvXrq1yA3BtczqdmjJlSpWPsXBtzJlnmC/PMF+eYb48w3x5pjbny2GMMX7fCgAAgB8E9T0yAAAANSHIAAAAaxFkAACAtQgyAADAWgSZb5g3b54SEhLUoEEDJSUlaceOHTX2f+edd3TbbbepQYMGuuuuu/TBBx+4rTfG6IUXXlBsbKwaNmyotLQ0HTx40J+7UKt8PV8jR46Uw+FwW3r16uXPXahVnszXvn37NGjQICUkJMjhcGju3Lk3PKZtfD1fU6dOrXJ83XbbbX7cg9rlyXz97ne/U/fu3dW0aVM1bdpUaWlpVfpz/vqn65mvun7+kjybs5UrV+qee+5RVFSUGjdurK5du+rNN9906+OzY8zAGGPM8uXLTVhYmFm0aJHZt2+fGT16tImKijJFRUXV9t+6dasJCQkxs2fPNvv37zfPP/+8qV+/vvnb3/7m6jNz5kwTGRlpVq1aZXbv3m1++MMfmjZt2ph//OMftbVbfuOP+crIyDC9evUyBQUFruXs2bO1tUt+5el87dixw0yYMMG89dZbJiYmxsyZM+eGx7SJP+ZrypQpplOnTm7H16lTp/y8J7XD0/kaPny4mTdvnsnLyzOffvqpGTlypImMjDTHjx939eH89U/XM191+fxljOdzlpuba1auXGn2799vDh06ZObOnWtCQkLM2rVrXX18dYwRZP7fvffea8aMGeN6XVFRYeLi4kxWVla1/f/93//d9O3b160tKSnJ/PSnPzXGGFNZWWliYmLMyy+/7FpfXFxsnE6neeutt/ywB7XL1/NlzJUTQf/+/f1Sb6B5Ol/fFB8fX+0/zDcyZrDzx3xNmTLFdOnSxYdVBo8bPRa+/vprEx4ebpYuXWqM4fz1Xb49X8bU7fOXMb453/zrv/6ref75540xvj3G+GhJ0qVLl/Txxx8rLS3N1VavXj2lpaVp27Zt1b5n27Ztbv0lKT093dX/8OHDKiwsdOsTGRmppKSka45pC3/M11WbNm1SixYt1LFjR/3sZz/TmTNnfL8Dtcyb+QrEmMHCn/t28OBBxcXFqW3btnr00Ud17NixGy034HwxXxcuXNDly5fVrFkzSZy/vsu35+uqunj+km58zowxysnJ0YEDB/T9739fkm+PMYKMpNOnT6uioqLKtwW3bNlShYWF1b6nsLCwxv5X/+vJmLbwx3xJUq9evbRs2TLl5ORo1qxZ2rx5s3r37q2Kigrf70Qt8ma+AjFmsPDXviUlJWnJkiVau3at5s+fr8OHD6t79+46d+7cjZYcUL6Yr1/+8peKi4tz/aPC+atm354vqe6evyTv56ykpERNmjRRWFiY+vbtq9/85jd68MEHJfn2GAv6P1GAm8fQoUNdP991113q3LmzEhMTtWnTJqWmpgawMtQFvXv3dv3cuXNnJSUlKT4+XitWrNCoUaMCWFlgzZw5U8uXL9emTZvUoEGDQJcT9K41X5y/qgoPD9euXbt0/vx55eTkKDMzU23btlWPHj18uh2uyEiKjo5WSEiIioqK3NqLiooUExNT7XtiYmJq7H/1v56MaQt/zFd12rZtq+joaB06dOjGiw4gb+YrEGMGi9rat6ioKHXo0OGmPr5eeeUVzZw5U+vWrVPnzp1d7Zy/qnet+apOXTl/Sd7PWb169dSuXTt17dpV48eP1+DBg5WVlSXJt8cYQUZSWFiY7r77buXk5LjaKisrlZOTo+Tk5Grfk5yc7NZfktavX+/q36ZNG8XExLj1KS0t1fbt2685pi38MV/VOX78uM6cOaPY2FjfFB4g3sxXIMYMFrW1b+fPn1d+fv5Ne3zNnj1b06dP19q1a3XPPfe4reP8VVVN81WdunL+knz3O1lZWany8nJJPj7GPLo1uA5bvny5cTqdZsmSJWb//v3mJz/5iYmKijKFhYXGGGN+9KMfmYkTJ7r6b9261YSGhppXXnnFfPrpp2bKlCnVPn4dFRVl3n//fbNnzx7Tv3//OvX4oi/n69y5c2bChAlm27Zt5vDhw2bDhg2mW7dupn379ubixYsB2Udf8nS+ysvLTV5ensnLyzOxsbFmwoQJJi8vzxw8ePC6x7SZP+Zr/PjxZtOmTebw4cNm69atJi0tzURHR5uTJ0/W+v75mqfzNXPmTBMWFmb+/Oc/uz0ufO7cObc+nL+u+K75quvnL2M8n7MZM2aYdevWmfz8fLN//37zyiuvmNDQUPO73/3O1cdXxxhB5ht+85vfmFtvvdWEhYWZe++913z00Ueudffff7/JyMhw679ixQrToUMHExYWZjp16mRWr17ttr6ystL86le/Mi1btjROp9OkpqaaAwcO1Mau1ApfzteFCxfMQw89ZJo3b27q169v4uPjzejRo+vEP8pXeTJfhw8fNpKqLPfff/91j2k7X8/XkCFDTGxsrAkLCzP/8i//YoYMGWIOHTpUi3vkX57MV3x8fLXzNWXKFFcfzl8ZrtffNV83w/nLGM/mbPLkyaZdu3amQYMGpmnTpiY5OdksX77cbTxfHWMOY4zx7BoOAABAcOAeGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACs9X8fIeExC0vDzwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_rouge = df['rougeL_score'].mean()\n",
        "print(f\"🔸 Overall ROUGE-L F1 Score: {overall_rouge:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CrPIQHDYtKV",
        "outputId": "f3143f0f-65fd-485c-f39c-e7229f03bc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔸 Overall ROUGE-L F1 Score: 0.0894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion:**\n",
        "\n",
        "**This project explores the use of pretrained neural machine translation models to translate the devotional ovis of Sant Tukaram from Marathi to English. Using the MarianMT (opus-mt-mr-en) model from Hugging Face, we translated a set of 100 manually curated ovis, each containing deep spiritual and poetic meaning.**\n",
        "\n",
        "**To evaluate the translation quality, we used the ROUGE-L F1 score, which measures the longest common subsequence between model and reference translations. ROUGE-L is particularly suitable for this task as it accounts for semantic similarity even when wording differs — unlike BLEU, which penalizes meaningful paraphrases.**\n",
        "\n",
        "#**Key Observations:**\n",
        "\n",
        "\n",
        "\n",
        "*   **Literal translation models often struggle with metaphor-rich, emotionally nuanced devotional texts like Tukaram's ovis.**\n",
        "*   **The average ROUGE-L scores ranged between 0.1 to 0.3, which is modest but reasonable given the abstract, poetic structure of the original content.**\n",
        "\n",
        "\n",
        "\n",
        "*  **Some model translations were contextually incorrect or overly generic, highlighting the limitations of out-of-domain pretrained models.**\n",
        "\n",
        "#**Insights & Future Scope :**\n",
        "\n",
        "\n",
        "\n",
        "*   **ROUGE-L outperformed BLEU for this type of poetic evaluation, which justifies its use in this project.**\n",
        "*   **To improve performance, the model could be fine-tuned on a larger corpus of Marathi devotional texts.**\n",
        "\n",
        "\n",
        "*  **Exploring IndicTrans2 or combining human post-editing with AI could yield more faithful and elegant translations.**"
      ],
      "metadata": {
        "id": "SQYIlsHieEha"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOzuau0KbbrE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}